_target_: trident.TridentDataModule
_recursive_: false

# defaults across built-in datamodules
defaults:
  # allows you to manually override on the cli with
  # python run.py tokenizer.padding=true
  - /tokenizer/trident@dataset_cfg._method_.map.function.tokenizer

dataset_cfg:
  _target_: datasets.load.load_dataset
  _method_: # get methods of _target_ object
    map: # dataset.map -> tokenization
      # kwargs for dataset.map
      function: ???
      batched: true
      num_proc: 1

datamodule_cfg:
  setup:
    _target_: trident.utils.data.setup
    _recursive_: false

dataloader_cfg:
  _target_: torch.utils.data.dataloader.DataLoader
  collate_fn:
    _target_: transformers.data.data_collator.DataCollatorWithPadding
    tokenizer:
      _target_: transformers.AutoTokenizer.from_pretrained
      pretrained_model_name_or_path: ${module.model.pretrained_model_name_or_path}
      padding: true

  batch_size: 32
  num_workers: 0
  pin_memory: true
  train:
    shuffle: true
  val:
    shuffle: false
  test:
    shuffle: false
